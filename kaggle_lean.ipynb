{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'vlaue_counts'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-82-2acd55df58a9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[0mx_RT_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxy\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"RT Seq\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[0mx_data\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mxy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Resp\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"PR Seq\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"RT Seq\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_RT_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvlaue_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[0my_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m#병에 걸린지 아닌지\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[0mx_PR_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\1project\\anaconda\\envs\\nlptensor\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5137\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5138\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5139\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5141\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Series' object has no attribute 'vlaue_counts'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "#염기서열은 g,c,a,t가 있다...\n",
    "\"\"\"\n",
    "모델 계획..\n",
    "1. 0또는 1을 구하는 것이므로 classification을 해야한다.\n",
    "2. classification은 결정트리, logistic알고리즘 등이 있다.\n",
    "3. 과적합을 방지하고 정확도를 높이기 위해 앙상블 기법을 사용한다.\n",
    "4. 모델을 test_data에 돌리고 정확도가 60% 이상이라면 kaggle에 올린다.\n",
    "\n",
    "\n",
    "문제점.... 피처엔지니어링의 중요성.....\n",
    "Q1. PR Seq, RT Seq의 DNA순서들을 어떻게 처리해야 텐서가 이해할 수 있을까...\n",
    "A1. one-hot encoding이 좋은 방안이 될수 있을것 같다...\n",
    "\n",
    "Q1-1. one-hot encode를 해도 데이터 길이가 일정하지 않다면 input_dim을 정해야 할때 문제가 생긴다.\n",
    "A1-1_1. 데이터의 패턴을 찾는 알고리즘을 짜고 길이를 일정하게 맞춘다면?\n",
    "A1-1_2. 가장 짧은 데이터를 기준으로 나머지를 잘라버린다..\n",
    "A1-1_3. 그냥 무작위를 부족한 만큼 넣는다.\n",
    "\n",
    "Q2. VL-t0, CD4-t0를 그냥 classification하면 둘다 숫자다 보니 정확도에 문제가 생긴다. 그럼 어떻게 처리해야할까?...\n",
    "Q3. PR Seq가 없는 데이터가 있는데 이 데이터들은 또 어떻게 처리해야할까...\n",
    "\"\"\"\n",
    "# Predicting animal type based on various features\n",
    "xy = pd.read_csv('./training_data.csv',dtype=None)\n",
    "\n",
    "xy.drop(['PatientID'], axis=1,inplace=True)\n",
    "#print(xy)\n",
    "\n",
    "y_data = xy[\"Resp\"]\n",
    "x_PR_data = xy[\"PR Seq\"]\n",
    "x_RT_data = xy[\"RT Seq\"]\n",
    "x_data =xy.drop([\"Resp\",\"PR Seq\",\"RT Seq\"], axis=1)\n",
    "\n",
    "y_data.to_numpy()  #병에 걸린지 아닌지\n",
    "x_PR_data.to_numpy()\n",
    "x_RT_data.to_numpy()\n",
    "x_data.to_numpy()  # 사람의 염기서열이나 어러 지표들\n",
    "\n",
    "#print(x_data)\n",
    "\n",
    "#y_data.count()\n",
    "#logistic classification\n",
    "#pr과 나머지로 나눠준다...\n",
    "#먼저 x_PR_data부터 train한다.\n",
    "\n",
    "\"\"\"\n",
    "tf_PR.model = tf.keras.Sequential()\n",
    "\n",
    "tf_PR.model.add(tf.keras.layers.Dense(units=1, input_dim=1))  \n",
    "tf_PR.model.add(tf.keras.layers.Activation('sigmoid'))\n",
    "\n",
    "\n",
    "tf.model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.SGD(lr=0.01), metrics=['accuracy'])\n",
    "tf.model.summary()\n",
    "\n",
    "history = tf.model.fit(x_data, y_data, epochs=5000)\n",
    "\n",
    "# Accuracy report\n",
    "print(\"Accuracy: \", history.history['accuracy'][-1])\n",
    "\n",
    "y_predict = tf.model.predict_classes(np.array([[5.1, 3.5 ,1.4, 0.2]]))\n",
    "print(y_predict)\n",
    "\"\"\"\n",
    "enc = OneHotEncoder()\n",
    "\n",
    "data=[[0,3,2,1,2,1,3,3,2,3]]\n",
    "data = np.array(data)\n",
    "data=data.reshape(-1,1)     #1차원 array를 2차원으로 만들어 준다.\n",
    "\n",
    "enc.fit(data)   #enc에 one-hot encoder class를 가져오고, \n",
    "data_onehot = enc.transform(data).toarray()  #원핫인코딩을 진행한다.\n",
    "#print(data_onehot)\n",
    "\n",
    "\n",
    "#x_PR_data\n",
    "def trans(x_PR_data):\n",
    "    xprdata=[]\n",
    "    for line in x_PR_data:\n",
    "        now=[]\n",
    "        #print(\"line=\",line)\n",
    "        try:\n",
    "            for gen in line:\n",
    "                if gen==\"C\":\n",
    "                    now.append(0)\n",
    "                elif gen==\"T\":\n",
    "                    now.append(1)\n",
    "                elif gen==\"A\":\n",
    "                    now.append(2)\n",
    "                else:\n",
    "                    now.append(3)\n",
    "            now=np.array(now)\n",
    "            now=now.reshape(-1,1)\n",
    "            enc.fit(now)\n",
    "            now = enc.transform(now).toarray()\n",
    "            xprdata.append(now)\n",
    "            #print(now)\n",
    "        except:\n",
    "            print(\"burn\")\n",
    "    return np.array(xprdata)\n",
    "x_PR_data=trans(x_PR_data)   #각A,G,T,C는 2차원 One-hot encode이고, 전체는 2차원의 합이므로 3차원이다.\n",
    "\n",
    "#print(x_PR_data)\n",
    "x_RT_data = trans(x_RT_data)\n",
    "print(\"\\n\\n\\n x_data==$$$$$$$$$$$$$\")\n",
    "x_RT_pd = pd.DataFrame(x_RT_data,columns=\"gtca\")\n",
    "print(x_RT_pd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
